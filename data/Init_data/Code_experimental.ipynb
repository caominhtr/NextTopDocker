{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem, DataStructs, PandasTools\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8693ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_tanimoto(train_id, test_id, df_init):\n",
    "    morgan_train = df_init[df_init['Entry ID'].isin(train_id)][['Ligand ID','Ligand SMILES','Morgan']].drop_duplicates('Ligand ID').reset_index(drop = True)\n",
    "    morgan_test = df_init[df_init['Entry ID'].isin(test_id)][['Ligand ID','Ligand SMILES','Morgan']].drop_duplicates('Ligand ID').reset_index(drop = True)\n",
    "\n",
    "    train_fps = list(morgan_train['Morgan'])\n",
    "    test_fps  = list(morgan_test['Morgan'])\n",
    "\n",
    "    similarity_matrix = np.zeros((len(train_fps), len(test_fps)))\n",
    "\n",
    "    for i, train_fp in enumerate(train_fps):\n",
    "        sims = DataStructs.BulkTanimotoSimilarity(train_fp, test_fps)\n",
    "        similarity_matrix[i, :] = np.round(sims, 4)  \n",
    "\n",
    "\n",
    "    df_similarity = pd.DataFrame(similarity_matrix)\n",
    "    df_similarity['max'] = df_similarity.max(axis = 1)\n",
    "    max_tanimoto = df_similarity['max'].max()\n",
    "\n",
    "    return max_tanimoto\n",
    "\n",
    "\n",
    "def logreg_model_dev(train_id, df_train, df_test, folds, df_PB):\n",
    "    \n",
    "    def objective(trial):\n",
    "        threshold = trial.suggest_float(\"threshold\", 0.01, 0.99)\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for i, fold_test in enumerate(folds):\n",
    "            fold_train = [key for j, fold in enumerate(folds) if j != i for key in fold]\n",
    "\n",
    "            df_train_CV = df_train[df_train['ID'].isin(fold_train)]\n",
    "            df_test_CV = df_train[df_train['ID'].isin(fold_test)]\n",
    "\n",
    "            X_train_CV = df_train_CV[['Smina', 'Gnina']]\n",
    "            y_train_CV = df_train_CV['Eval']\n",
    "            X_test_CV = df_test_CV[['Smina','Gnina']]\n",
    "            y_test_CV = df_test_CV['Eval']\n",
    "\n",
    "            scale = StandardScaler()\n",
    "            X_train_scaled = scale.fit_transform(X_train_CV)\n",
    "            X_test_scaled = scale.transform(X_test_CV)\n",
    "\n",
    "            model = LogisticRegression()\n",
    "            model.fit(X_train_scaled, y_train_CV)\n",
    "            y_prob_test = model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "            y_pred_test = (y_prob_test >= threshold).astype(int)\n",
    "            result.append(balanced_accuracy_score(y_test_CV, y_pred_test))\n",
    "\n",
    "        return np.mean(result)\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    sampler = TPESampler(seed=36)  \n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    optimal_thres = round(study.best_params['threshold'],4)\n",
    "\n",
    "\n",
    "    train_subset = df_train[df_train['ID'].isin(train_id)]\n",
    "\n",
    "    X_train = train_subset[['Smina','Gnina']]\n",
    "    y_train = train_subset['Eval']\n",
    "    X_test = df_test[['Smina','Gnina']]\n",
    "    y_test = df_test['Eval']\n",
    "\n",
    "    scale = StandardScaler()\n",
    "    X_train_scaled = scale.fit_transform(X_train)\n",
    "    X_test_scaled = scale.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_prob_test = model.predict_proba(X_test_scaled)[:,1]\n",
    "    y_pred_test = (y_prob_test >= optimal_thres).astype(int)\n",
    "    acc_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    test_copy = df_test.copy()\n",
    "    test_copy['Pred'] = y_prob_test\n",
    "    test_ = test_copy.sort_values(['ID','RMSD'])\n",
    "    test_new = test_.loc[test_.groupby('ID')['Pred'].nlargest(1,keep='first').index.get_level_values(1)]\n",
    "    DP_test = test_new[test_new['Eval']==1].shape[0]/5201\n",
    "\n",
    "    PB_new = df_PB[df_PB['Pose'].isin(test_new[test_new['Eval']==1]['Pose'])]\n",
    "    DP_PB_test = PB_new.iloc[:,3:29].all(axis = 1).sum() / 5201\n",
    "\n",
    "    acc_CV = []\n",
    "    for i, fold_test in enumerate(folds):\n",
    "        fold_train = [key for j, fold in enumerate(folds) if j != i for key in fold]\n",
    "\n",
    "        df_train_CV = df_train[df_train['ID'].isin(fold_train)]\n",
    "        df_test_CV = df_train[df_train['ID'].isin(fold_test)]\n",
    "\n",
    "        X_train_CV = df_train_CV[['Smina', 'Gnina']]\n",
    "        y_train_CV = df_train_CV['Eval']\n",
    "        X_test_CV = df_test_CV[['Smina', 'Gnina']]\n",
    "        y_test_CV = df_test_CV['Eval']\n",
    "\n",
    "        scale = StandardScaler()\n",
    "        X_train_scaled = scale.fit_transform(X_train_CV)\n",
    "        X_test_scaled = scale.transform(X_test_CV)\n",
    "\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train_scaled, y_train_CV)\n",
    "        y_prob_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        y_pred_test = (y_prob_test >= optimal_thres).astype(int)\n",
    "\n",
    "        acc = balanced_accuracy_score(y_test_CV, y_pred_test)\n",
    "        acc_CV.append(acc)\n",
    "    \n",
    "    return round(DP_test,4), round(DP_PB_test,4), optimal_thres, round(acc_test,4), round(np.mean(acc_CV), 4), round(np.std(acc_CV), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ace1c",
   "metadata": {},
   "source": [
    "### Calculating the highest similarity between each training-(sub)set and all test set ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_init.csv')\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "PandasTools.AddMoleculeColumnToFrame(df, 'Ligand SMILES', 'Structure')\n",
    "df['Morgan'] = df['Structure'].apply(lambda mol:AllChem.GetMorganFingerprintAsBitVect (mol, 2, 2048))\n",
    "\n",
    "test_id = pd.read_csv(f'../NextTopDocker_ID/Training_Test/test.csv', header = None)\n",
    "test_id = test_id.iloc[:,0]\n",
    "\n",
    "for i in np.arange(10, 101, 10):\n",
    "    train_id = pd.read_csv(f'../NextTopDocker_ID/Training_Test/train_{i}.csv', header = None)\n",
    "    train_id = train_id.iloc[:,0]\n",
    "\n",
    "    max_tanimoto = calc_max_tanimoto(train_id, test_id, df)\n",
    "\n",
    "    print(f\"Training set LogReg ({i}%): {max_tanimoto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3de69",
   "metadata": {},
   "source": [
    "### Develop 10 LogReg (x%) models and assess their docking power and classification power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('df_train.csv')\n",
    "test = pd.read_csv('df_test.csv')\n",
    "\n",
    "PB = pd.read_csv('Test_PoseBuster.csv')\n",
    "PB['Pose'] = PB['file'].apply(lambda x: str(x).split('/')[-1].split('.')[0])\n",
    "\n",
    "\n",
    "for i in np.arange(10, 101, 10):\n",
    "    train_id = pd.read_csv(f'../NextTopDocker_ID/Training_Test/train_{i}.csv', header = None)\n",
    "    train_id = train_id.iloc[:,0]\n",
    "\n",
    "    with open(f'../NextTopDocker_ID/5CV_ID/5CV_train_{i}.pkl', 'rb') as f:\n",
    "        folds = pickle.load(f)\n",
    "\n",
    "    result = logreg_model_dev(train_id, train, test, folds, PB)\n",
    "\n",
    "    print(f\"LogReg ({i}%)\")\n",
    "    print(f\"Docking power: DP test ({result[0]}), DP test with PB ({result[1]})\")\n",
    "    print(f\"Classification power: Optimal threshold ({result[2]}), BA on test ({result[3]}), BA on 5CV ({result[4]} +- {result[5]}))\")\n",
    "    print(\"----------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f4cd3",
   "metadata": {},
   "source": [
    "### Analysis docking power of SOTA end-to-end ML docking tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepDock\n",
    "print(\"DeepDock results:\")\n",
    "df_deepdock_RMSD = pd.read_csv(\"../Result_SOTA/DeepDock_final_RMSD.csv\")\n",
    "print(f\"DP: {round(df_deepdock_RMSD[df_deepdock_RMSD['RMSD']<=2].shape[0]/5201,4)}\")\n",
    "\n",
    "df_deepdock_PB = pd.read_csv(\"../Result_SOTA/DeepDock_PoseBuster.csv\")\n",
    "print(f\"DP with PB: {round(df_deepdock_PB.iloc[:,3:29].all(axis = 1).sum()/5201,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34102ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interformer (Energy Score)\n",
    "print(\"Interformer (Energy Score) results:\")\n",
    "\n",
    "df_int_energy_RMSD = pd.read_csv(\"../Result_SOTA/Interformer_energy_final_RMSD.csv\")\n",
    "df_int_energy_RMSD = df_int_energy_RMSD.sort_values(['Target','rmsd'])\n",
    "df_int_energy_RMSD = df_int_energy_RMSD.loc[df_int_energy_RMSD.groupby('Target')['energy'].nsmallest(1, keep='first').index.get_level_values(1)]\n",
    "print(f\"DP: {round(df_int_energy_RMSD[df_int_energy_RMSD['rmsd']<=2].shape[0]/5201,4)}\")\n",
    "\n",
    "df_int_energy_PB = pd.read_csv(\"../Result_SOTA/Interformer_energy_PoseBuster.csv\")\n",
    "df_int_energy_PB['Pose'] = df_int_energy_PB['file'].apply(lambda x: str(x).split('/')[-1].split('_')[0])\n",
    "df_int_energy_PB = df_int_energy_PB[df_int_energy_PB['Pose'].isin(df_int_energy_RMSD[df_int_energy_RMSD['rmsd']<=2]['Target'])]\n",
    "print(f\"DP with PB: {round(df_int_energy_PB.iloc[:,3:29].all(axis = 1).sum()/5201,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interformer (Pose Score)\n",
    "print(\"Interformer (Pose Score) results:\")\n",
    "\n",
    "df_int_posescore_RMSD = pd.read_csv(\"../Result_SOTA/Interformer_posescore_final_RMSD.csv\")\n",
    "df_int_posescore_RMSD = df_int_posescore_RMSD.sort_values(['Target','rmsd'])\n",
    "df_int_posescore_RMSD = df_int_posescore_RMSD.loc[df_int_posescore_RMSD.groupby('Target')['pred_pose'].nlargest(1, keep='first').index.get_level_values(1)]\n",
    "print(f\"DP: {round(df_int_posescore_RMSD[df_int_posescore_RMSD['rmsd']<=2].shape[0]/5201,4)}\")\n",
    "\n",
    "df_int_posescore_PB = pd.read_csv(\"../Result_SOTA/Interformer_posescore_PoseBuster.csv\")\n",
    "df_int_posescore_PB['Pose'] = df_int_posescore_PB['file'].apply(lambda x: str(x).split('/')[-1].split('_')[0])\n",
    "df_int_posescore_PB = df_int_posescore_PB[df_int_posescore_PB['Pose'].isin(df_int_posescore_RMSD[df_int_posescore_RMSD['rmsd']<=2]['Target'])]\n",
    "print(f\"DP with PB: {round(df_int_posescore_PB.iloc[:,3:29].all(axis = 1).sum()/5201,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SurfDock\n",
    "print(\"SurfDock results:\")\n",
    "\n",
    "df_surfdock_RMSD = pd.read_csv(\"../Result_SOTA/SurfDock_final_RMSD.csv\", header = None)\n",
    "df_surfdock_RMSD.columns = ['ID','RMSD']\n",
    "print(f\"DP: {round(df_surfdock_RMSD[df_surfdock_RMSD['RMSD']<=2].shape[0]/5201, 4)}\")\n",
    "\n",
    "df_surfdock_PB = pd.read_csv(\"../Result_SOTA/SurfDock_PoseBuster.csv\")\n",
    "df_surfdock_PB['Pose'] = df_surfdock_PB['molecule'].apply(lambda x: str(x).split('_')[0])\n",
    "df_surfdock_PB = df_surfdock_PB[df_surfdock_PB['Pose'].isin(df_surfdock_RMSD[df_surfdock_RMSD['RMSD']<=2]['ID'])]\n",
    "print(f\"DP with PB: {round(df_surfdock_PB.iloc[:,3:29].all(axis = 1).sum()/5201, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uni-Mol Docking v.2\n",
    "print(\"Uni-Mol Docking v.2 results:\")\n",
    "\n",
    "df_UM2_RMSD = pd.read_csv(\"../Result_SOTA/UM2_final_RMSD.csv\", header = None)\n",
    "df_UM2_RMSD.columns = ['ID','RMSD']\n",
    "print(f\"DP: {round(df_UM2_RMSD[df_UM2_RMSD['RMSD']<=2].shape[0]/5201, 4)}\")\n",
    "\n",
    "df_UM2_PB = pd.read_csv(\"../Result_SOTA/UM2_PoseBuster.csv\")\n",
    "df_UM2_PB['Pose'] = df_UM2_PB['file'].apply(lambda x: str(x).split('/')[1])\n",
    "df_UM2_PB = df_UM2_PB[df_UM2_PB['Pose'].isin(df_UM2_RMSD[df_UM2_RMSD['RMSD']<=2]['ID'])]\n",
    "print(f\"DP with PB: {round(df_UM2_PB.iloc[:,3:29].all(axis = 1).sum()/5201, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NextTopDocker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
